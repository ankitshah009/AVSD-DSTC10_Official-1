# AVSD-DSTC10 Official
  Audio Visual Scene-Aware Dialog (AVSD) Challenge at the 10th Dialog System Technology Challenge (DSTC)
  [https://sites.google.com/dstc.community/dstc10](https://sites.google.com/dstc.community/dstc10)


## News

The baseline system and the validation data for reasoning timing will be released soon.
    
### Please [Register HERE](https://docs.google.com/forms/d/e/1FAIpQLSe9CgrlygYciIZH_pK8133fbp1kqigTB6JIP7utfNFx_xSm6A/viewform) for participating in the challenge


## Goal: Reasoning for Audio Visual Scene-Aware Dialog

    The task setup for the previous challenges in DSTC7 and DSTC8 allowed the participants 
    to use human-created video captions to generate answers for the dialog questions. 
    However, such manual descriptions are not available in real-world applications, where the 
    system needs to learn to produce the answers without the captions. 
    To encourage progress towards this end, we propose a third challenge
    in DSTC10 under the video-based scene-aware dialog track. 
    In this challenge, we seek evidence from the system to support the generated answer 
    via detecting the temporal segments in the videos corresponding to the answer.
    
## Challenge schedule

    June 14th, 2021: Answer generation data release
    June 30th, 2021: Answer reasoning temporal localization data and baseline release: 
       Sorry for delay. Coming soon!
       **Releasing answer reasoning to registrants only**
  
    September 13th, 2021: Test Data release
    September 21st 2021: Test Submission due
    November 1st 2021: Challenge paper submission due
    January or February, 2022: Workshop

## Task definition
#### Task 1: Video QA dialog
    Goal: Answer generation without using manual descriptions for inference
    You can train models using manual descriptions but CANNOT use them for testing. 
    Video description capability needs to be embedded within the answer generation models.
    
    Data conditions:
    a. Use the provided video including audio and video features, 
       the dialog history and manual video descriptions (scripts and summary) data for training
        - text descriptions or scripts used by the actor to enact in the videos
        - summary generated by the questioners after holding 10 QAs.

    b. Publicly available external data and pre-trained models may also be used for training as a sub task

#### Task 2: Reasoning Video QA dialog
    Goal: Answer reasoning temporal Localization 

    To support answers, evidence is required to be shown without using manual descriptions. 
    For example, When a system generated answer is “A dog is barking.”, the sound of the dog’s barking and
    the dog must be grounded in the video as evidence.
    The localization of audiovisual evidence is required for each generated answer.
    To train reasoning localization, begin and end timing of the grounding/evidence will be additionally provided for the training data.

    Data conditions:
    a. Temporal localization information for answer reasoning is provided as begin and end timestamps showing evidence scenes
    b. Any publicly available data and pre-trained models may also be used for training as a sub task.
 
##### Data Collection Method for Reasoning
![Data Collection for reasoning](https://github.com/dialogtekgeek/AVSD-DSTC10_Official/blob/main/InstructionForReasoning.png)

## Data set: Video Data from Charades dataset
    Video dat: CHARADES for human action recognition datasets.
        https://allenai.org/plato/charades/
   
        *The original videos of the test sets of the official Charades Challenge
          https://ai2-public-datasets.s3-us-west-2.amazonaws.com/charades/Charades_vu17_test.tar [13Gb]
          https://ai2-public-datasets.s3-us-west-2.amazonaws.com/charades/Charades_vu17_test_480.tar [2Gb]

#### Validation data set:
Please train models using the training data set only.
You can tune the parameters using the validation set and confirm the performance of your systems using the DSTC10 test sets.
Notes: The official challenge doesn't allow you to use the DSTC10 test set to tune your models.

|               |    Training    |  Validation   |   DSTC10 Test  |
| ------------- | -------------- | ------------- | ------------- |
| # of Dialogs  |       7,659    |      1,787    |      1,710    |   
| # of Turns    |     153,180    |     35,740    |     13,490    |
| # of Words    |   1,450,754    |    339,006    |    110,252    |

*The number of turns for the test set is smaller than the validation
because they are not always full dialogs.

Please review the following information on how to download annotations set, feature representations and evaluation setup for AVSD@DSTC10.

### 1. Text files:

* **train_set4DSTC10-AVSD.json**
  Training text files (train_set4DSTC10-AVSD.json) - Contains summary, caption, question answer pairs, **action with its timestamps**. 
   
* **valid_set4DSTC10-AVSD_with_action.json**
  Validation text file (valid_set4DSTC10-AVSD_with_action.json) - contains question answer pairs, **action with its timestamps**.
 
* **valid_set4DSTC10-AVSD.json**
  Validation text file (valid_set4DSTC10-AVSD.json) - contains question answer pairs 
 
* **mock_test_set4DSTC10-AVSD_from_DSTC7_singref.json**
  Mock Test text file from DSTC7 (mock_test_set4DSTC10-AVSD_from_DSTC7_singref.json) - contains question answer pairs only from DSTC7-test set

* **mock_test_set4DSTC10-AVSD_from_DSTC8_singref.json**
  Mock Test text file from DSTC8 (mock_test_set4DSTC10-AVSD_from_DSTC8_singref.json) - contains question answer pairs only from DSTC8-test set
  
[Annotation Data Download here](https://github.com/dialogtekgeek/AVSD-DSTC10_Official/blob/main/AnswerGeneration_NoManualDescription_06_14_2021.zip) 

OR

```
You can do a git clone of this repository
git clone https://github.com/dialogtekgeek/AVSD-DSTC10_Official/ and then 
cd AVSD-DSTC10_Official/
unzip AnswerGeneration_NoManualDescription_06_14_2021.zip
```

### 2. Audio feature files:

[Download Audio features from DSTC7 Here](https://drive.google.com/drive/folders/12Ri617jeV1XfMjcDQf5camyRXGrVW5u3?usp=sharing)

* Training and validation data sets  
   * vggish.tgz 
* Test set:
   * vggish_testset.tgz: 

### 3. Visual feature files:

[Download Visual features from DSTC7 Here](https://drive.google.com/drive/folders/12R7OtjcXAgxZiFi2fOSG8miFiqi0ewL2?usp=sharing)

- Training and validation data sets:   
  - i3d_flow.tgz 
  - i3d_rgb.tgz
- Test set:
  - i3d_flow_testset.tgz
  - i3d_rgb_testset.tgz

### 4. DSTC10 evaluation setup for Mock

#### DSTC10 official baseline system
Download DSTC10 baseline system from here:
GitHub_Link:

#### Task 1. Video QA dialog: Answer generation evaluation using multiple answers
[Download DSTC7 Evaluation for mock test set here](https://drive.google.com/file/d/19Jmm4HNXSwcg-sL7jktlCalakPCIhnxm/view?usp=sharing)
- dstc7avsd_eval.tgz

[Download DSTC8 Evaluation for mock test set here](https://drive.google.com/file/d/1EKfPtrNBQ5ciKRl6XggImweGRP84XuPi/view?usp=sharing)
- dstc8avsd_eval.tgz

   ```
   For the evaluation using mock test set where the "__UNDISCLOSED__" needs to be replaced by your system answers
   - the evaluation tool from DSTC7 and DSTC8 is provided here
   ```
   The baseline system for DSTC7 and DSTC8 is available from the following link:
   https://github.com/dialogtekgeek/AudioVisualSceneAwareDialog

   You can find more information in the following DSTC7-AVSD overview paper:
   http://workshop.colips.org/dstc7/papers/DSTC10_Task_3_overview_paper.pdf

   Links to the previous related AVSD track in DSTC7 and DSTC8 challenge: 
   
   [AVSD DSTC7 GitHub link](https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge)
   
   [AVSD DSTC8 GitHub Link](https://github.com/dialogtekgeek/DSTC8-AVSD_official)

#### Task 2. Reasoning Video QA dialog: Answer generation with reasoning timing using single answer
Please use the evaluation package in the DSTC10 official baseline system.


### - Contact Information

#### Join the DSTC mailing list to get the latest updates about DSTC10
* To join the mailing list: visit https://groups.google.com/a/dstc.community/forum/#!forum/list/join

* To post a message: send your message to list@dstc.community

* To leave the mailing list: visit https://groups.google.com/a/dstc.community/forum/#!forum/list/unsubscribe

#### DSTC10 Task4 specific inquiries 

[Chiori Hori](mailto:chori@merl.com) & [Ankit Shah](mailto:aps1@andrew.cmu.edu)

### Task Organizers

Ankit Shah, Shijie Geng, Peng Gao, Anoop Cherian, Chiori Hori and Tim K. Marks
