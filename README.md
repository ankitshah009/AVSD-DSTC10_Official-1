# AVSD-DSTC10 Official
  Audio Visual Scene-Aware Dialog (AVSD) Challenge at the 10th Dialog System Technology Challenge (DSTC)
  [https://sites.google.com/dstc.community/dstc10](https://sites.google.com/dstc.community/dstc10)


## News

The baseline system and the validation data for reasoning timing will be released soon.
    
### Please [Register HERE](https://docs.google.com/forms/d/e/1FAIpQLSe9CgrlygYciIZH_pK8133fbp1kqigTB6JIP7utfNFx_xSm6A/viewform) for participating in the challenge


## Goal: Reasoning for Audio Visual Scene-Aware Dialog

    The task setup for the previous challenges in DSTC7 and DSTC8 allowed the participants 
    to use human-created video captions to generate answers for the dialog questions. 
    However, such manual descriptions are not available in real-world applications, where the 
    system needs to learn to produce the answers without the captions. 
    To encourage progress towards this end, we propose a third challenge
    in DSTC10 under the video-based scene-aware dialog track. 
    In this challenge, we seek evidence from the system to support the generated answer 
    via detecting the temporal segments in the videos corresponding to the answer.
    
## Challenge schedule

    June 14th, 2021: Answer generation data release
    June 30th, 2021: Answer reasoning temporal localization data and baseline release: 
       Sorry for delay. Coming soon!
       **Releasing answer reasoning to registrants only**
  
    September 13th, 2021: Test Data release
    September 21st 2021: Test Submission due
    November 1st 2021: Challenge paper submission due
    January or February, 2022: Workshop

## Task definition
#### Task 1: Video QA dialog
    Goal: Answer generation without using manual descriptions for inference
    You can train models using manual descriptions but CANNOT use them for testing. 
    Video description capability needs to be embedded within the answer generation models.
    
    Data conditions:
    a. Use the provided video including audio and video features, 
       the dialog history and manual video descriptions (scripts and summary) data for training
        - text descriptions or scripts used by the actor to enact in the videos
        - summary generated by the questioners after holding 10 QAs.

    b. Publicly available external data and pre-trained models may also be used for training as a sub task

#### Task 2: Reasoning Video QA dialog
    Goal: Answer reasoning temporal Localization 

    To support answers, evidence is required to be shown without using manual descriptions. 
    For example, When a system generated answer is “A dog is barking.”, the sound of the dog’s barking and
    the dog must be grounded in the video as evidence.
    The localization of audiovisual evidence is required for each generated answer.
    To train reasoning localization, begin and end timing of the grounding/evidence will be additionally provided for the training data.

    Data conditions:
    a. Temporal localization information for answer reasoning is provided as begin and end timestamps showing evidence scenes
    b. Any publicly available data and pre-trained models may also be used for training as a sub task.
 
##### Data Collection Method for Reasoning
![Data Collection for reasoning](https://github.com/dialogtekgeek/AVSD-DSTC10_Official/blob/main/InstructionForReasoning.png)


### 4. DSTC10 evaluation setup for Mock

#### DSTC10 official baseline system
Download DSTC10 baseline system from here:
GitHub_Link:

#### Task 1. Video QA dialog: Answer generation evaluation using multiple answers
[Download DSTC7 Evaluation for mock test set here](https://drive.google.com/file/d/19Jmm4HNXSwcg-sL7jktlCalakPCIhnxm/view?usp=sharing)
- dstc7avsd_eval.tgz

[Download DSTC8 Evaluation for mock test set here](https://drive.google.com/file/d/1EKfPtrNBQ5ciKRl6XggImweGRP84XuPi/view?usp=sharing)
- dstc8avsd_eval.tgz

   ```
   For the evaluation using mock test set where the "__UNDISCLOSED__" needs to be replaced by your system answers
   - the evaluation tool from DSTC7 and DSTC8 is provided here
   ```
   The baseline system for DSTC7 and DSTC8 is available from the following link:
   https://github.com/dialogtekgeek/AudioVisualSceneAwareDialog

   You can find more information in the following DSTC7-AVSD overview paper:
   http://workshop.colips.org/dstc7/papers/DSTC10_Task_3_overview_paper.pdf

   Links to the previous related AVSD track in DSTC7 and DSTC8 challenge: 
   
   [AVSD DSTC7 GitHub link](https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge)
   
   [AVSD DSTC8 GitHub Link](https://github.com/dialogtekgeek/DSTC8-AVSD_official)

#### Task 2. Reasoning Video QA dialog: Answer generation with reasoning timing using single answer
Please use the evaluation package in the DSTC10 official baseline system.


### - Contact Information

#### Join the DSTC mailing list to get the latest updates about DSTC10
* To join the mailing list: visit https://groups.google.com/a/dstc.community/forum/#!forum/list/join

* To post a message: send your message to list@dstc.community

* To leave the mailing list: visit https://groups.google.com/a/dstc.community/forum/#!forum/list/unsubscribe

#### DSTC10 Task4 specific inquiries 

[Chiori Hori](mailto:chori@merl.com) & [Ankit Shah](mailto:aps1@andrew.cmu.edu)

### Task Organizers

Ankit Shah, Shijie Geng, Peng Gao, Anoop Cherian, Chiori Hori and Tim K. Marks
